{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a572300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57b063f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aae7949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNo</th>\n",
       "      <th>date</th>\n",
       "      <th>heading</th>\n",
       "      <th>body</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>414</td>\n",
       "      <td>11-05-2017 00:39:13</td>\n",
       "      <td>ఐడిబిఐపై ఆర్‌బిఐ నజర్‌</td>\n",
       "      <td>భారీ ఎత్తున మొండిబకాయిలు పెరిగిపోవడంతో ఐడిబిఐ ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2668</td>\n",
       "      <td>12-06-2017 00:40:32</td>\n",
       "      <td>బ్యాంకింగ్‌ చీఫ్‌లతో నేడు జైట్లీ భేటీ</td>\n",
       "      <td>న్యూఢిల్లీ : ఆర్థిక మంత్రి అరుణ్‌ జైట్లీ సోమవా...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19923</td>\n",
       "      <td>19-01-2017 19:51:31</td>\n",
       "      <td>కీలక వికెట్ తీసిన జడేజా..</td>\n",
       "      <td>కటక్: ఇంగ్లండ్‌తో జరుగుతున్న సెకండ్ వన్డే మ్యా...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15762</td>\n",
       "      <td>23-11-2017 17:29:04</td>\n",
       "      <td>మరో రెచ్చగొట్టే చర్యకు దిగిన పాకిస్థాన్</td>\n",
       "      <td>\\nఇస్లామాబాద్ : పాకిస్థాన్ అంతర్జాతీయ ఉగ్రవాది...</td>\n",
       "      <td>nation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8624</td>\n",
       "      <td>03-04-2017 15:48:23</td>\n",
       "      <td>గోవాలో కొడుకుతో కలిసి అల్లు అర్జున్ స్విమ్మింగ్!</td>\n",
       "      <td>స్టార్‌ హీరోగా వరుస సినిమాలతో బిజీగా ఉన్నప్పటి...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17307</th>\n",
       "      <td>10296</td>\n",
       "      <td>02-02-2017 12:18:11</td>\n",
       "      <td>చిరు,ఎన్టీఆర్ వల్ల కాజల్‌కు దక్కిందేమిటి..?</td>\n",
       "      <td>ఇండస్ట్రీలో హీరోయిన్‌గా రాణించాలంటే కేవలం గ్లా...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17308</th>\n",
       "      <td>13641</td>\n",
       "      <td>20-12-2017 04:16:32</td>\n",
       "      <td>హిమాచల్‌ సీఎం రేసులో నడ్డా, జైరామ్‌</td>\n",
       "      <td>షిమ్లా, డిసెంబరు 19: హిమాచల్‌ ప్రదేశ్‌ అసెంబ్ల...</td>\n",
       "      <td>nation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17309</th>\n",
       "      <td>17288</td>\n",
       "      <td>20-05-2017 03:00:10</td>\n",
       "      <td>సతతహరిత విప్లవం అవసరం</td>\n",
       "      <td>2022 నాటికి  రైతుల ఆదాయం రెట్టింపు చేయడానికి క...</td>\n",
       "      <td>nation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17310</th>\n",
       "      <td>20882</td>\n",
       "      <td>13-06-2017 04:30:36</td>\n",
       "      <td>ఇంగ్లండ్‌ జెర్సీలో వార్న్‌..!</td>\n",
       "      <td>పందెంలో ఓడిన షేనలండన్: ఆస్ట్రేలియా స్పిన్ లెజె...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17311</th>\n",
       "      <td>13905</td>\n",
       "      <td>17-12-2017 02:12:54</td>\n",
       "      <td>ఆ శక్తి రాహుల్‌కు ఉంది!</td>\n",
       "      <td>ధైర్యంగా పార్టీని నడపగలరు దేశం సవాళ్లను ఎదుర్...</td>\n",
       "      <td>nation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17312 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SNo                 date  \\\n",
       "0        414  11-05-2017 00:39:13   \n",
       "1       2668  12-06-2017 00:40:32   \n",
       "2      19923  19-01-2017 19:51:31   \n",
       "3      15762  23-11-2017 17:29:04   \n",
       "4       8624  03-04-2017 15:48:23   \n",
       "...      ...                  ...   \n",
       "17307  10296  02-02-2017 12:18:11   \n",
       "17308  13641  20-12-2017 04:16:32   \n",
       "17309  17288  20-05-2017 03:00:10   \n",
       "17310  20882  13-06-2017 04:30:36   \n",
       "17311  13905  17-12-2017 02:12:54   \n",
       "\n",
       "                                                heading  \\\n",
       "0                                ఐడిబిఐపై ఆర్‌బిఐ నజర్‌   \n",
       "1                 బ్యాంకింగ్‌ చీఫ్‌లతో నేడు జైట్లీ భేటీ   \n",
       "2                             కీలక వికెట్ తీసిన జడేజా..   \n",
       "3               మరో రెచ్చగొట్టే చర్యకు దిగిన పాకిస్థాన్   \n",
       "4      గోవాలో కొడుకుతో కలిసి అల్లు అర్జున్ స్విమ్మింగ్!   \n",
       "...                                                 ...   \n",
       "17307       చిరు,ఎన్టీఆర్ వల్ల కాజల్‌కు దక్కిందేమిటి..?   \n",
       "17308               హిమాచల్‌ సీఎం రేసులో నడ్డా, జైరామ్‌   \n",
       "17309                             సతతహరిత విప్లవం అవసరం   \n",
       "17310                     ఇంగ్లండ్‌ జెర్సీలో వార్న్‌..!   \n",
       "17311                           ఆ శక్తి రాహుల్‌కు ఉంది!   \n",
       "\n",
       "                                                    body          topic  \n",
       "0      భారీ ఎత్తున మొండిబకాయిలు పెరిగిపోవడంతో ఐడిబిఐ ...       business  \n",
       "1      న్యూఢిల్లీ : ఆర్థిక మంత్రి అరుణ్‌ జైట్లీ సోమవా...       business  \n",
       "2      కటక్: ఇంగ్లండ్‌తో జరుగుతున్న సెకండ్ వన్డే మ్యా...         sports  \n",
       "3      \\nఇస్లామాబాద్ : పాకిస్థాన్ అంతర్జాతీయ ఉగ్రవాది...         nation  \n",
       "4      స్టార్‌ హీరోగా వరుస సినిమాలతో బిజీగా ఉన్నప్పటి...  entertainment  \n",
       "...                                                  ...            ...  \n",
       "17307  ఇండస్ట్రీలో హీరోయిన్‌గా రాణించాలంటే కేవలం గ్లా...  entertainment  \n",
       "17308  షిమ్లా, డిసెంబరు 19: హిమాచల్‌ ప్రదేశ్‌ అసెంబ్ల...         nation  \n",
       "17309  2022 నాటికి  రైతుల ఆదాయం రెట్టింపు చేయడానికి క...         nation  \n",
       "17310  పందెంలో ఓడిన షేనలండన్: ఆస్ట్రేలియా స్పిన్ లెజె...         sports  \n",
       "17311   ధైర్యంగా పార్టీని నడపగలరు దేశం సవాళ్లను ఎదుర్...         nation  \n",
       "\n",
       "[17312 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = \"train_telugu_news.csv\"\n",
    "\n",
    "telugu_news_df = pd.read_csv(train_path)\n",
    "telugu_news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c8569ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "del telugu_news_df[\"heading\"]\n",
    "del telugu_news_df[\"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a7e59f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from indicnlp.tokenize import sentence_tokenize, indic_tokenize\n",
    "from indicnlp.normalize.indic_normalize import IndicNormalizerFactory\n",
    "\n",
    "def preprocess_text(text):\n",
    "    sentences = sentence_tokenize.sentence_split(text, lang='te')\n",
    "    tokenizer = indic_tokenize.trivial_tokenize\n",
    "\n",
    "    preprocessed_sentences = []\n",
    "    for sentence in sentences:\n",
    "        sentence = re.sub('[^\\u0C00-\\u0C7F]+', ' ', sentence)\n",
    "        words = tokenizer(sentence)\n",
    "        filtered_words = [word for word in words if word.strip() and not re.match(r'^[.,!?]+$|^[\"\\'()\\[\\]]+$', word)]\n",
    "        preprocessed_sentence = ' '.join(filtered_words)\n",
    "        preprocessed_sentences.append(preprocessed_sentence)\n",
    "\n",
    "    preprocessed_text = ' '.join(preprocessed_sentences)\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27c79d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SNo                                               body          topic\n",
      "0    414  భారీ ఎత్తున మొండిబకాయిలు పెరిగిపోవడంతో ఐడిబిఐ ...       business\n",
      "1   2668  న్యూఢిల్లీ ఆర్థిక మంత్రి అరుణ్ జైట్లీ సోమవారం ...       business\n",
      "2  19923  కటక్ ఇంగ్లండ్ తో జరుగుతున్న సెకండ్ వన్డే మ్యాచ...         sports\n",
      "3  15762  ఇస్లామాబాద్ పాకిస్థాన్ అంతర్జాతీయ ఉగ్రవాది హపీ...         nation\n",
      "4   8624  స్టార్ హీరోగా వరుస సినిమాలతో బిజీగా ఉన్నప్పటిక...  entertainment\n"
     ]
    }
   ],
   "source": [
    "telugu_news_df['body'] = telugu_news_df['body'].apply(preprocess_text)\n",
    "print(telugu_news_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdb851e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_mapping = {'business': 0, 'sports': 1, 'nation': 2, 'entertainment': 3, 'editorial': 4}\n",
    "telugu_news_df['topic'] = telugu_news_df['topic'].replace(topic_mapping)\n",
    "telugu_news_df[\"topic\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d54ff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = telugu_news_df['body'].tolist()\n",
    "labels = telugu_news_df['topic'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6286c1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "input_ids = []\n",
    "attention_masks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0c329b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in text_data:\n",
    "    encoded = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "    input_ids.append(encoded['input_ids'])\n",
    "    attention_masks.append(encoded['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67649408",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tf.concat(input_ids, axis=0)\n",
    "attention_masks = tf.concat(attention_masks, axis=0)\n",
    "labels = tf.convert_to_tensor(labels)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_size = int(0.8 * len(input_ids))\n",
    "train_input_ids, test_input_ids = input_ids[:train_size], input_ids[train_size:]\n",
    "train_attention_masks, test_attention_masks = attention_masks[:train_size], attention_masks[train_size:]\n",
    "train_labels, test_labels = labels[:train_size], labels[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be46ef43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d1b054e3374fb09df0497589dfda07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Define the BERT model for sequence classification\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=5)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87d5a5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  177853440 \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  3845      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,857,285\n",
      "Trainable params: 177,857,285\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38eb67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      " 12/433 [..............................] - ETA: 2:19:46 - loss: 1.5673 - accuracy: 0.3099"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=[train_input_ids, train_attention_masks],\n",
    "    y=train_labels,\n",
    "    epochs=4,\n",
    "    batch_size=32,\n",
    "    validation_data=([test_input_ids, test_attention_masks], test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8405dba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_texts = [\"ఈ చిత్రం చాలా మంచిది\", \"నేను ఈ పుస్తకాన్ని చదవగలను\"]\n",
    "new_input_ids = []\n",
    "new_attention_masks = []\n",
    "\n",
    "for text in new_texts:\n",
    "    encoded = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "    new_input_ids.append(encoded['input_ids'])\n",
    "    new_attention_masks.append(encoded['attention_mask'])\n",
    "\n",
    "new_input_ids = tf.concat(new_input_ids, axis=0)\n",
    "new_attention_masks = tf.concat(new_attention_masks, axis=0)\n",
    "\n",
    "predictions = model.predict([new_input_ids, new_attention_masks])\n",
    "predicted_labels = tf.argmax(predictions.logits, axis=1).numpy()\n",
    "\n",
    "for text, label in zip(new_texts, predicted_labels):\n",
    "    print(\"Text:\", text)\n",
    "    print(\"Predicted Label:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134dcaa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
